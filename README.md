# ğŸ§¹ Data Cleaning - Nashville Housing Dataset  

## ğŸ“Œ Overview  
This project aims to demonstrate the importance of the **data cleaning** stage in any data analysis workflow.  
For this purpose, I used the **Nashville Housing dataset**, applying SQL techniques to fix inconsistencies, remove duplicates, and standardize information.  

With cleaner and more consistent data, future analysis and insights become **more accurate and reliable**.  

---

## ğŸ¯ Project Goal  
- Correct and standardize inconsistent information in the dataset.  
- Handle null values and replace them logically.  
- Create new columns from existing data, making the dataset more structured.  
- Remove duplicates and unnecessary columns, leaving the dataset ready for analysis.  

---

## ğŸ—‚ï¸ Data Cleaning Steps  

### 1ï¸âƒ£ Standardizing Dates  
- The `SaleDate` column was in **datetime** format, containing both date and time.  
- Applied:  
  ```sql
  CONVERT(date, SaleDate)
to keep only the date, ensuring consistency.

### 2ï¸âƒ£ Fixing Missing Property Addresses
Some rows were missing PropertyAddress.
Using ParcelID, I matched and filled in missing addresses from other records.

code used:
ISNULL(a.PropertyAddress, b.PropertyAddress)

### 3ï¸âƒ£ Splitting Address Columns
Property addresses were stored in a single column.

Used functions like SUBSTRING, CHARINDEX, LTRIM, and RTRIM to split into:
AddressProperty â†’ street
City â†’ city

For OwnerAddress, I applied PARSENAME (after replacing commas with periods) to extract:
OwnerSplitAddress â†’ street
OwnerCity â†’ city
OwnerState â†’ state

### 4ï¸âƒ£ Standardizing Categorical Variables
The column SoldAsVacant contained numeric values (0 and 1).

Converted them into text values for better readability:
CASE 
    WHEN SoldAsVacant = 0 THEN 'No'
    WHEN SoldAsVacant = 1 THEN 'Yes'
END

### 5ï¸âƒ£ Removing Duplicates
Duplicate records were detected in the dataset.

I used ROW_NUMBER() with PARTITION BY to identify duplicates and kept only the first valid record.

Example:
ROW_NUMBER() OVER (
  PARTITION BY ParcelID, PropertyAddress, SalePrice, SaleDate, LegalReference
  ORDER BY UniqueID
) row_num

Then, records with row_num > 1 were deleted.

### 6ï¸âƒ£ Dropping Unused Columns
After cleaning and creating new structured columns, old redundant columns were removed:
OwnerAddress
PropertyAddress

### ğŸ› ï¸ Key SQL Functions Used
UPDATE â†’ to fix null values and standardize data.
PARSENAME â†’ to split parts of strings (addresses).
ROW_NUMBER() â†’ to detect duplicates.
LTRIM, RTRIM â†’ to remove unnecessary spaces.
ISNULL â†’ to fill missing values.

### ğŸ“Š Summary
The data cleaning process is a crucial step in any data project. In this case study, I:
âœ”ï¸ Standardized date formats.
âœ”ï¸ Fixed missing and unstructured addresses.
âœ”ï¸ Created new columns from unorganized data.
âœ”ï¸ Standardized categorical variables.
âœ”ï¸ Removed duplicates and unused information.

As a result, the dataset is now much cleaner, standardized, and ready for accurate and reliable analysis.
